{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aae678f5-94da-40cf-a94b-9673bda04db3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "PRE REQUISITE\n",
    "- paramiko\n",
    "- python-gnupg\n",
    "- com.microsoft.azure:spark-mssql-connector_2.12:1.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63e28b75-f3bf-4b0f-95e9-26725a84b0cd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Initialize variable"
    }
   },
   "outputs": [],
   "source": [
    "# Input from workflow\n",
    "dbutils.widgets.text(\"book\",\"default\")\n",
    "\n",
    "# Define file paths and database parameters\n",
    "book = dbutils.widgets.get(\"book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3825bd09-2745-4950-8580-f59fe2499138",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Connect to SFTP and download encrypted file"
    }
   },
   "outputs": [],
   "source": [
    "import paramiko\n",
    "import os\n",
    "import datetime\n",
    "import calendar\n",
    "import fnmatch  # For pattern matching\n",
    "import tempfile\n",
    "import subprocess\n",
    "import gnupg\n",
    "\n",
    "# SFTP server credentials\n",
    "sftp_host = \"sftp.nipgroup.com\"\n",
    "sftp_port = 22\n",
    "sftp_username = dbutils.secrets.get(scope = \"nip-scope-dev\", key = \"nip-sftp-dev-username\")\n",
    "sftp_password = dbutils.secrets.get(scope = \"nip-scope-dev\", key = \"nip-sftp-dev-password\")\n",
    "\n",
    "# Remote directory path\n",
    "remote_directory = \"/incoming/\"\n",
    "\n",
    "# Databricks file system (DBFS) path\n",
    "mnt_sftp_path = \"/dbfs/mnt/sftp/\"\n",
    "\n",
    "# Chunk size for downloading (1MB)\n",
    "CHUNK_SIZE = 1024 * 1024\n",
    "\n",
    "# Filename patterns to match\n",
    "patterns = [\"CLAIM\",\"EXPOSURE\",\"ORGANIZATION\",\"POLICY\",\"PREMIUM\"]\n",
    "\n",
    "# Get current month and year\n",
    "current_date = datetime.datetime.now()\n",
    "current_month = current_date.month - 1 # Deduct 1 month as data pushed covers the previous month\n",
    "month_name = calendar.month_name[current_month]\n",
    "current_year = current_date.year\n",
    "last_day = calendar.monthrange(current_year, current_month)[1]\n",
    "date_suffix = f\"{current_year:04d}{current_month:02d}{last_day:02d}\"\n",
    "\n",
    "# Connect to SFTP\n",
    "try:\n",
    "    # Create an SFTP client\n",
    "    transport = paramiko.Transport((sftp_host, sftp_port))\n",
    "    transport.connect(username=sftp_username, password=sftp_password)\n",
    "    sftp = paramiko.SFTPClient.from_transport(transport)\n",
    "    transport.set_keepalive(30)  # Keep connection alive every 30 seconds\n",
    "    print(\"Successfully connected to SFTP server.\\n\")\n",
    "\n",
    "    # List files in the remote directory\n",
    "    files = sftp.listdir(remote_directory)\n",
    "    \n",
    "    # Get file metadata and filter files from the current month and year\n",
    "    filtered_files = []\n",
    "    for file in files:\n",
    "        # Determine the file pattern based on the book parameter\n",
    "        if book == \"jif\":\n",
    "            file_pattern = \"I2I_JIF_{pattern}_NIP_{date_suffix}*\"\n",
    "        elif book == \"program\":\n",
    "            file_pattern = \"I2I_Programs_{pattern}_NIP_{date_suffix}*\"\n",
    "        else:\n",
    "            file_pattern = \"I2I_{pattern}_NIP_{date_suffix}*\"\n",
    "        \n",
    "        # Check if filename matches any pattern\n",
    "        if any(fnmatch.fnmatch(file, file_pattern.format(pattern=pattern, date_suffix=date_suffix)) for pattern in patterns):\n",
    "            filtered_files.append(file)\n",
    "    \n",
    "    # Check if any files were found\n",
    "    if filtered_files.__len__() == 0:\n",
    "        dbutils.notebook.exit(\"No files found for the current month and year.\")\n",
    "\n",
    "    # Get file metadata and filter the file sizes\n",
    "    files_to_download = [\n",
    "        (file, sftp.stat(os.path.join(remote_directory, file)).st_size) \n",
    "        for file in filtered_files\n",
    "    ]\n",
    "\n",
    "    # Sort files by size (ascending)\n",
    "    files_to_download.sort(key=lambda x: x[1])\n",
    "\n",
    "    # Download filtered files to DBFS temp directory\n",
    "    sftp_files_path = [] # Store the downloaded encrypted file paths for later use\n",
    "    for file_obj in files_to_download:\n",
    "        file = file_obj[0] # File name\n",
    "        sftp_path = os.path.join(mnt_sftp_path, file) # Blob container path, mounted\n",
    "        sftp_files_path.append(sftp_path)\n",
    "        remote_file_path = os.path.join(remote_directory, file) # Remote file path\n",
    "\n",
    "        # Download the file to DBFS temp directory with the same name as the remote file\n",
    "        with sftp.open(remote_file_path, \"rb\") as remote_file, open(sftp_path, \"wb\") as downloadable_file:\n",
    "            while True:\n",
    "                data = remote_file.read(CHUNK_SIZE)\n",
    "                if not data:\n",
    "                    break\n",
    "                downloadable_file.write(data)\n",
    "                \n",
    "            print(f\"File {file} downloaded successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    if 'sftp' in locals():\n",
    "        sftp.close()\n",
    "    if 'transport' in locals():\n",
    "        transport.close()\n",
    "    dbutils.notebook.exit(f\"Error connecting to SFTP: {e}\")\n",
    "finally:\n",
    "    if 'sftp' in locals():\n",
    "        sftp.close()\n",
    "    if 'transport' in locals():\n",
    "        transport.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dade193d-302b-49d3-9562-8ce5f336444d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Decrypt SFTP File and store it in lake"
    }
   },
   "outputs": [],
   "source": [
    "# Path to encrypted files and decryption output\n",
    "mnt_pgp_path = \"/dbfs/mnt/pgp/\"\n",
    "mnt_sas_path = \"/dbfs/mnt/sas/\"\n",
    "\n",
    "with tempfile.TemporaryDirectory() as gnupghome:\n",
    "    os.environ[\"GNUPGHOME\"] = gnupghome\n",
    "    gpg = gnupg.GPG()\n",
    "\n",
    "    pgps = os.listdir(mnt_pgp_path)\n",
    "    gpg_key_path = None\n",
    "\n",
    "    for pgp_file in pgps:\n",
    "        if pgp_file.endswith(\"SECRET.asc\"):\n",
    "            gpg_key_path = os.path.join(mnt_pgp_path, pgp_file)\n",
    "\n",
    "    # Read and import the GPG key\n",
    "    with open(gpg_key_path, \"r\") as key_file:\n",
    "        key_data = key_file.read()\n",
    "        import_result = gpg.import_keys(key_data)\n",
    "        keyid = import_result.fingerprints[0]\n",
    "        gpg.trust_keys(keyid, \"TRUST_ULTIMATE\")\n",
    "\n",
    "    # List imported keys\n",
    "    imported_keys = gpg.list_keys(secret=True)\n",
    "\n",
    "    if not imported_keys:\n",
    "        raise Exception(\"No secret key found. Ensure the correct PGP private key is imported.\")\n",
    "    else:\n",
    "        print(\"Secret key successfully imported.\")\n",
    "\n",
    "    # Use variable where the stored downloaded encrypted file path in the sftp mount - 'stfp_files_path'\n",
    "    for sftp_file in sftp_files_path: # Use the sftp mounted path variable from previous notebook\n",
    "        sas_file = sftp_file.replace(mnt_sftp_path, mnt_sas_path).replace(\".gpg\", \"\").replace(\".pgp\", \"\")\n",
    "        \n",
    "        gpg_command = [\n",
    "            'gpg',  \n",
    "            '--output', sas_file,\n",
    "            '--decrypt',\n",
    "            sftp_file\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            subprocess.run(gpg_command, check=True, capture_output=True, text=True)\n",
    "            print(f\"Decryption successful for file: {sftp_file}.\")\n",
    "            print(f\"Decrypted file is in: {sas_file}.\\n\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Decryption failed for file: {sftp_file}.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "sftp_decrypt_to_blob_store",
   "widgets": {
    "book": {
     "currentValue": "jif",
     "nuid": "89ea7afd-4359-4ebb-9073-4ee41cfa27df",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "default",
      "label": null,
      "name": "book",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "default",
      "label": null,
      "name": "book",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
