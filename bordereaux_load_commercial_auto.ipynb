{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be6d3ef5-8aca-4ed3-b4e6-65fd6e00ce64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table_name = \"commercial_auto\"\n",
    "year = \"2019\"\n",
    "                     \n",
    "excel_file_path = f\"/mnt/bordereaux/bronze/{year}/{table_name}-bordereaux-{year}.csv\"\n",
    "delta_table = f\"hive_metastore.bordereaux.{table_name}\"\n",
    "\n",
    "df = spark.read.csv(\n",
    "    excel_file_path,\n",
    "    header=True,\n",
    "    inferSchema=False,\n",
    "    multiLine=True,         # In case some fields have line breaks\n",
    "    quote='\"',              # Properly handle comma-separated quoted fields\n",
    "    escape='\"',             # Handle quotes inside quoted fields\n",
    "    mode=\"PERMISSIVE\"       # Handle malformed lines gracefully\n",
    ")\n",
    "\n",
    "# Then load data in the bordereaux delta table\n",
    "df.write.format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(delta_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ae405b1-bd9b-4ad6-8f8b-2cd104a48995",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table_name = \"commercial_auto\"\n",
    "year = \"2020\"\n",
    "                     \n",
    "excel_file_path = f\"/mnt/bordereaux/bronze/{year}/{table_name}-bordereaux-{year}.csv\"\n",
    "delta_table = f\"hive_metastore.bordereaux.{table_name}\"\n",
    "\n",
    "df = spark.read.csv(\n",
    "    excel_file_path,\n",
    "    header=True,\n",
    "    inferSchema=False,\n",
    "    multiLine=True,         # In case some fields have line breaks\n",
    "    quote='\"',              # Properly handle comma-separated quoted fields\n",
    "    escape='\"',             # Handle quotes inside quoted fields\n",
    "    mode=\"PERMISSIVE\"       # Handle malformed lines gracefully\n",
    ")\n",
    "\n",
    "# Then load data in the bordereaux delta table\n",
    "df.write.format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(delta_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "960fd448-24dd-411d-b09f-e673adb231a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table_name = \"commercial_auto\"\n",
    "year = \"2021\"\n",
    "                     \n",
    "excel_file_path = f\"/mnt/bordereaux/bronze/{year}/{table_name}-bordereaux-{year}.csv\"\n",
    "delta_table = f\"hive_metastore.bordereaux.{table_name}\"\n",
    "\n",
    "df = spark.read.csv(\n",
    "    excel_file_path,\n",
    "    header=True,\n",
    "    inferSchema=False,\n",
    "    multiLine=True,         # In case some fields have line breaks\n",
    "    quote='\"',              # Properly handle comma-separated quoted fields\n",
    "    escape='\"',             # Handle quotes inside quoted fields\n",
    "    mode=\"PERMISSIVE\"       # Handle malformed lines gracefully\n",
    ")\n",
    "\n",
    "# Then load data in the bordereaux delta table\n",
    "df.write.format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(delta_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c3cf660-6a6d-4100-b93a-2d7dff005b52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table_name = \"commercial_auto\"\n",
    "year = \"2022\"\n",
    "                     \n",
    "excel_file_path = f\"/mnt/bordereaux/bronze/{year}/{table_name}-bordereaux-{year}.csv\"\n",
    "delta_table = f\"hive_metastore.bordereaux.{table_name}\"\n",
    "\n",
    "df = spark.read.csv(\n",
    "    excel_file_path,\n",
    "    header=True,\n",
    "    inferSchema=False,\n",
    "    multiLine=True,         # In case some fields have line breaks\n",
    "    quote='\"',              # Properly handle comma-separated quoted fields\n",
    "    escape='\"',             # Handle quotes inside quoted fields\n",
    "    mode=\"PERMISSIVE\"       # Handle malformed lines gracefully\n",
    ")\n",
    "\n",
    "# Then load data in the bordereaux delta table\n",
    "df.write.format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(delta_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c493534-4f3d-497c-a1ad-d689b109e206",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table_name = \"commercial_auto\"\n",
    "year = \"2023\"\n",
    "                     \n",
    "excel_file_path = f\"/mnt/bordereaux/bronze/{year}/{table_name}-bordereaux-{year}.csv\"\n",
    "delta_table = f\"hive_metastore.bordereaux.{table_name}\"\n",
    "\n",
    "df = spark.read.csv(\n",
    "    excel_file_path,\n",
    "    header=True,\n",
    "    inferSchema=False,\n",
    "    multiLine=True,         # In case some fields have line breaks\n",
    "    quote='\"',              # Properly handle comma-separated quoted fields\n",
    "    escape='\"',             # Handle quotes inside quoted fields\n",
    "    mode=\"PERMISSIVE\"       # Handle malformed lines gracefully\n",
    ")\n",
    "\n",
    "# Then load data in the bordereaux delta table\n",
    "df.write.format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(delta_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e3e5d96-2c3c-447a-b186-05ce4973bb79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table_name = \"commercial_auto\"\n",
    "year = \"2024\"\n",
    "                     \n",
    "excel_file_path = f\"/mnt/bordereaux/bronze/{year}/{table_name}-bordereaux-{year}.csv\"\n",
    "delta_table = f\"hive_metastore.bordereaux.{table_name}\"\n",
    "\n",
    "df = spark.read.csv(\n",
    "    excel_file_path,\n",
    "    header=True,\n",
    "    inferSchema=False,\n",
    "    multiLine=True,         # In case some fields have line breaks\n",
    "    quote='\"',              # Properly handle comma-separated quoted fields\n",
    "    escape='\"',             # Handle quotes inside quoted fields\n",
    "    mode=\"PERMISSIVE\"       # Handle malformed lines gracefully\n",
    ")\n",
    "\n",
    "# Then load data in the bordereaux delta table\n",
    "df.write.format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(delta_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "882a56c0-7bb7-43c5-8ef3-236acb133ac2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table_name = \"commercial_auto\"\n",
    "year = \"2025\"\n",
    "                     \n",
    "excel_file_path = f\"/mnt/bordereaux/bronze/{year}/{table_name}-bordereaux-{year}.csv\"\n",
    "delta_table = f\"hive_metastore.bordereaux.{table_name}\"\n",
    "\n",
    "df = spark.read.csv(\n",
    "    excel_file_path,\n",
    "    header=True,\n",
    "    inferSchema=False,\n",
    "    multiLine=True,         # In case some fields have line breaks\n",
    "    quote='\"',              # Properly handle comma-separated quoted fields\n",
    "    escape='\"',             # Handle quotes inside quoted fields\n",
    "    mode=\"PERMISSIVE\"       # Handle malformed lines gracefully\n",
    ")\n",
    "\n",
    "# Then load data in the bordereaux delta table\n",
    "df.write.format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(delta_table)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bordereaux_load_commercial_auto",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
