# Databricks notebook source
# Databricks notebook source
from pyspark.sql import SparkSession

# Create a Spark session
spark_session = SparkSession.builder.appName("nip_refined").getOrCreate()
# SQL code without %sql magic command
sql_code = """CREATE OR REPLACE TABLE nip_refined.exposures (
  as_of DATE,
  book STRING,
  account_name STRING,
  specialty_program STRING,
  carrier STRING,
  LOB STRING,
  aop_deductible STRING,
  address_1 STRING,
  address_2 STRING,
  building_limit FLOAT,
  building_number STRING,
  city STRING,
  class_code STRING,
  construction STRING,
  construction_class STRING,
  contents_limit FLOAT,
  coverage STRING,
  coverage_reference STRING,
  created_by STRING,
  created_by_data_process STRING,
  exposure_created_date DATE,
  created_date_rc_exp DATE,
  deductible FLOAT,
  deductible_type STRING,
  eq_deductible FLOAT,
  eq_limit FLOAT,
  endorsement_number FLOAT,
  expos_dt DATE,
  expos_eff_dt DATE,
  expos_exp_dt DATE,
  exposure_type STRING,
  expos_yr FLOAT,
  final_audit_value STRING,
  flood_deductible FLOAT,
  flood_limit FLOAT,
  id_for_data_loads STRING,
  insured_name STRING,
  last_updated_by STRING,
  last_updated_date DATE,
  load_notes STRING,
  location_number STRING,
  mac_id STRING,
  nbfu_fire_protection_class STRING,
  number_of_stories STRING,
  occupancy_type STRING,
  organization STRING,
  personal_stock FLOAT,
  pol_eff_dt DATE,
  pol_exp_dt DATE,
  policy_id_for_data_loads STRING,
  postal_code STRING,
  primary_coverage STRING,
  property_location_postal_code STRING,
  public_protection_class STRING,
  rc_record_id FLOAT,
  record_id_sort_order STRING,
  record_id STRING,
  risk_reference STRING,
  segment_product STRING,
  source_file_name STRING,
  policy_number STRING,
  square_footage FLOAT,
  insured_state STRING,
  stock FLOAT,
  subline_load STRING,
  time_element_limit FLOAT,
  unit_number FLOAT,
  unit_count FLOAT,
  unit_make STRING,
  unit_model STRING,
  unit_model_year FLOAT,
  unit_radius STRING,
  unit_territory STRING,
  unit_type STRING,
  vin STRING,
  value FLOAT,
  value_currency FLOAT,
  vehicle_class STRING,
  wind_method STRING,
  wind_hail_ded_amnt STRING,
  wind_hail_ded_pct STRING,
  wind_hail_exclusion STRING,
  year_built FLOAT,
  base_rate FLOAT,
  subline_code STRING,
  vehicle_base_zone STRING,
  vehicle_size STRING,
  vehicle_terminal_zone STRING,
  vehicle_use STRING,
  exposures FLOAT)
;
"""
spark_session.sql(sql_code)
