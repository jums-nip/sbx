{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c06daf5-ec40-4607-a4fd-14c63728d606",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create schema if not exists"
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "\n",
    "# CREATE SCHEMA IF NOT EXISTS hive_metastore.bordereaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecee6bbd-f246-43f3-b239-5edc6e4ee282",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_name = \"agricultural-bordereaux-2019.csv\"\n",
    "table_name = \"agricultural\"\n",
    "excel_file_path = f\"/mnt/bordereaux/bronze/{file_name}\"\n",
    "\n",
    "delta_table = f\"hive_metastore.bordereaux.{table_name}\"\n",
    "\n",
    "# Read the CSV file into a Spark DataFrame\n",
    "agricultural_df = spark.read.csv(excel_file_path, header=True, inferSchema=True)\n",
    "# display(agricultural_df)\n",
    "\n",
    "agricultural_df.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"truncate\", \"true\") \\\n",
    "        .saveAsTable(delta_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "183e63c2-0da2-4c5c-9312-e8bef22426e5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "load crime"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "file_name = \"crime-bordereaux-2019.csv\"\n",
    "table_name = \"crime\"\n",
    "excel_file_path = f\"/mnt/bordereaux/bronze/{file_name}\"\n",
    "\n",
    "delta_table = f\"hive_metastore.bordereaux.{table_name}\"\n",
    "\n",
    "# Read the CSV file into a Spark DataFrame\n",
    "crime_df = spark.read.csv(excel_file_path, header=True, inferSchema=True)\n",
    "# display(crime_df)\n",
    "\n",
    "crime_df.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"truncate\", \"true\") \\\n",
    "        .saveAsTable(delta_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16bfdad5-63b1-4453-b403-2d7c668aaa1e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "load inland marine"
    }
   },
   "outputs": [],
   "source": [
    "file_name = \"inland_marine-bordereaux-2019.csv\"\n",
    "table_name = \"inland_marine\"\n",
    "excel_file_path = f\"/mnt/bordereaux/bronze/{file_name}\"\n",
    "\n",
    "delta_table = f\"hive_metastore.bordereaux.{table_name}\"\n",
    "\n",
    "# Read the CSV file into a Spark DataFrame\n",
    "inland_marine_df = spark.read.csv(excel_file_path, header=True, inferSchema=True)\n",
    "# display(inland_marine_df)\n",
    "\n",
    "inland_marine_df.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"truncate\", \"true\") \\\n",
    "        .saveAsTable(delta_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f532546f-b445-4e98-8dee-01729a8370af",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "load liability"
    }
   },
   "outputs": [],
   "source": [
    "file_name = \"liability-bordereaux-2019.csv\"\n",
    "table_name = \"liability\"\n",
    "excel_file_path = f\"/mnt/bordereaux/bronze/{file_name}\"\n",
    "\n",
    "delta_table = f\"hive_metastore.bordereaux.{table_name}\"\n",
    "\n",
    "# Read the CSV file into a Spark DataFrame\n",
    "liability_df = spark.read.csv(excel_file_path, header=True, inferSchema=True)\n",
    "# display(liability_df)\n",
    "\n",
    "liability_df.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"truncate\", \"true\") \\\n",
    "        .saveAsTable(delta_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e61379e6-c6aa-44ce-82d0-543e7a79f8bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_name = \"property-bordereaux-2019.csv\"\n",
    "table_name = \"property\"\n",
    "excel_file_path = f\"/mnt/bordereaux/bronze/{file_name}\"\n",
    "\n",
    "delta_table = f\"hive_metastore.bordereaux.{table_name}\"\n",
    "\n",
    "# Read the CSV file into a Spark DataFrame\n",
    "property_df = spark.read.csv(excel_file_path, header=True, inferSchema=True)\n",
    "# display(property_df)\n",
    "\n",
    "property_df.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"truncate\", \"true\") \\\n",
    "        .saveAsTable(delta_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a84f073-2e20-484c-b12c-69fb6b64a689",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_name = \"property-bordereaux-2019.csv\"\n",
    "table_name = \"property\"\n",
    "excel_file_path = f\"/mnt/bordereaux/bronze/{file_name}\"\n",
    "\n",
    "delta_table = f\"hive_metastore.bordereaux.{table_name}\"\n",
    "\n",
    "# Read the CSV file into a Spark DataFrame\n",
    "property_df = spark.read.csv(excel_file_path, header=True, inferSchema=True)\n",
    "# display(property_df)\n",
    "\n",
    "property_df.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"truncate\", \"true\") \\\n",
    "        .saveAsTable(delta_table)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4769103220215510,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "bordereaux_load",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
